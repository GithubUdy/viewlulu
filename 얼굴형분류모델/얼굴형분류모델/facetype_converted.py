# -*- coding: utf-8 -*-
# ------------------------------------------------------------
# Image classification of Human Face Shapes Using CNN Xception
#  - Training setì„ ë¬´ì‘ìœ„ 6:4ë¡œ ë¶„í• í•˜ì—¬ í•™ìŠµ/ê²€ì¦ ì§„í–‰ (validation_split=0.4)
#  - Testing setì€ ìµœì¢… ì„±ëŠ¥ í‰ê°€ìš©ìœ¼ë¡œë§Œ ì‚¬ìš©
#  - ëª¨ë¸: Xception(include_top=False) + GAP + Dense(512â†’128â†’Softmax)
#  - Epoch: 20, EarlyStopping/Checkpoint ì ìš©
#  - ì§€í‘œ: ì •í™•ë„/ì†ì‹¤ ê³¡ì„ , í˜¼ë™í–‰ë ¬, ë¶„ë¥˜ë¦¬í¬íŠ¸, í´ë˜ìŠ¤ë³„ ê°œìˆ˜, ì¤‘ë³µ íŒŒì¼ ì²´í¬
# ------------------------------------------------------------

import os
import random
import numpy as np
import matplotlib.pyplot as plt
from PIL import ImageFile

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img
from tensorflow.keras import layers, models
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from tensorflow.keras.layers import Dropout
from tensorflow.keras.applications import Xception
from tensorflow.keras.applications.xception import preprocess_input

from sklearn.metrics import confusion_matrix, classification_report

# GUI ì—†ëŠ” í™˜ê²½ì—ì„œë„ ì €ì¥ ê°€ëŠ¥í•˜ë„ë¡ (í•„ìš” ì‹œ ì£¼ì„)
# import matplotlib
# matplotlib.use("Agg")

# ---------------------------
# 0) ì•ˆì •ì  ì¬í˜„ì„± ì„¤ì •
# ---------------------------
SEED = 42
random.seed(SEED)
np.random.seed(SEED)
tf.random.set_seed(SEED)

# í° ì´ë¯¸ì§€ ë¡œë“œ ì‹œ ì˜ë¦° ì´ë¯¸ì§€ë„ í—ˆìš©
ImageFile.LOAD_TRUNCATED_IMAGES = True

# ---------------------------
# 1) ê²½ë¡œ ì„¤ì • (ë„¤ ê¸°ì¡´ ê²½ë¡œ ìœ ì§€)
# ---------------------------
train_dir = r"C:\Users\yuji2\FaceShape Dataset\training_set"
test_dir  = r"C:\Users\yuji2\FaceShape Dataset\testing_set"

# ---------------------------
# 2) í´ë˜ìŠ¤ ë°¸ëŸ°ì‹± ìœ í‹¸ (ë„¤ ì½”ë“œ ìœ ì§€/ë³´ì™„)
#    - Square í´ë˜ìŠ¤ ë‹¤ìš´ìƒ˜í”Œë§
#    - ê° í´ë˜ìŠ¤ 3000ì¥ ë§ì¶¤ ì¦ê°•
# ---------------------------
def reduce_square_images(directory, target_count=3000):
    """Square í´ë˜ìŠ¤ ì´ë¯¸ì§€ ìˆ˜ë¥¼ target_countë¡œ ë§ì¶”ê¸°(ê³¼ì‰ë¶„ ì œê±°)"""
    if not os.path.isdir(directory):
        print(f"[WARN] ë””ë ‰í† ë¦¬ ì—†ìŒ: {directory}")
        return
    all_images = [f for f in os.listdir(directory)
                  if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
    excess = len(all_images) - target_count
    if excess <= 0:
        print(f"âœ… Square: {len(all_images)}ì¥ (ì‚­ì œ ë¶ˆí•„ìš”)")
        return
    print(f"ğŸ—‘ï¸ Square: {len(all_images)}ì¥ â†’ {target_count}ì¥ìœ¼ë¡œ ë§ì¶”ê¸° (ì‚­ì œ {excess}ì¥)")
    delete_images = random.sample(all_images, excess)
    for fname in delete_images:
        try:
            os.remove(os.path.join(directory, fname))
        except Exception as e:
            print(f"[WARN] ì‚­ì œ ì‹¤íŒ¨: {fname} ({e})")
    now_cnt = len([f for f in os.listdir(directory)
                   if f.lower().endswith(('.jpg', '.jpeg', '.png'))])
    print("âœ… ì‚­ì œ ì™„ë£Œ! í˜„ì¬ ì´ë¯¸ì§€ ìˆ˜:", now_cnt)

# íŒŒì¼ ìƒì„±í˜• ì¦ê°•ê¸° (í•™ìŠµ ì „ìš© ë°ì´í„° ìˆ˜ ëŠ˜ë¦¬ê¸°)
augmentor = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.1,
    height_shift_range=0.1,
    zoom_range=0.1,
    horizontal_flip=True,
    fill_mode='nearest'
)

def augment_images(src_dir, target_count):
    """src_dir ë‚´ ì´ë¯¸ì§€ ìˆ˜ê°€ target_countì— ë¯¸ë‹¬í•˜ë©´, íŒŒì¼ ìƒì„±í˜• ì¦ê°•ìœ¼ë¡œ ì±„ì›€"""
    if not os.path.isdir(src_dir):
        print(f"[WARN] ë””ë ‰í† ë¦¬ ì—†ìŒ: {src_dir}")
        return
    imgs = [f for f in os.listdir(src_dir)
            if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
    image_count = len(imgs)
    needed = target_count - image_count
    if needed <= 0:
        print(f"âœ… {os.path.basename(src_dir)}: {image_count}ì¥ (ì¦ê°• ë¶ˆí•„ìš”)")
        return

    print(f"â• {os.path.basename(src_dir)}: {image_count}â†’{target_count} (ì¦ê°• {needed}ì¥ ìƒì„±)")
    generated = 0
    for img_name in imgs:
        if not img_name.lower().endswith(('.jpg', '.jpeg', '.png')):
            continue
        img_path = os.path.join(src_dir, img_name)
        try:
            img = load_img(img_path)
        except Exception as e:
            print(f"[WARN] ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {img_path} ({e})")
            continue

        x = img_to_array(img)
        x = x.reshape((1,) + x.shape)

        for _ in augmentor.flow(
            x, batch_size=1, save_to_dir=src_dir, save_prefix='aug', save_format='jpg'
        ):
            generated += 1
            if generated >= needed:
                break
        if generated >= needed:
            break
    print(f"âœ… {generated}ì¥ ìƒì„± ì™„ë£Œ")

# ---------------------------
# 3) í´ë˜ìŠ¤ ë°¸ëŸ°ì‹± ì‹¤í–‰ (í•„ìš” ì‹œ ì£¼ì„ ì²˜ë¦¬ ê°€ëŠ¥)
# ---------------------------
reduce_square_images(os.path.join(train_dir, "Square"), target_count=3000)
for cls in ["Heart", "Oblong", "Oval", "Round"]:
    augment_images(os.path.join(train_dir, cls), 3000)

# ---------------------------
# 4) ë°ì´í„° ë¡œë”©
#    - í›ˆë ¨ ì„¸íŠ¸ë¥¼ 6:4ë¡œ ë¬´ì‘ìœ„ ë¶„í•  (validation_split=0.4)
#    - í…ŒìŠ¤íŠ¸ì…‹ì€ ìµœì¢… í‰ê°€ì—ë§Œ ì‚¬ìš©
# ---------------------------
target_size = (224, 224)
batch_size = 32

# Xception ì „ì²˜ë¦¬(preprocess_input)ë¥¼ ì‚¬ìš©
train_datagen = ImageDataGenerator(
    preprocessing_function=preprocess_input,
    width_shift_range=0.1,
    height_shift_range=0.1,
    zoom_range=0.15,
    horizontal_flip=True,
    validation_split=0.4   # 40%ë¥¼ ê²€ì¦ìœ¼ë¡œ ì‚¬ìš© â†’ í•™ìŠµ:ê²€ì¦ = 6:4
)
# ê²€ì¦ë„ ê°™ì€ ì œë„ˆë ˆì´í„°ë¡œ subset='validation'
val_datagen = ImageDataGenerator(
    preprocessing_function=preprocess_input,
    validation_split=0.4
)
# í…ŒìŠ¤íŠ¸ëŠ” ì „ì²˜ë¦¬ë§Œ ì ìš©
test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=target_size,
    batch_size=batch_size,
    class_mode='categorical',
    subset='training',      # 60%
    shuffle=True,
    seed=SEED
)

print("class_indices:", train_generator.class_indices)

val_generator = val_datagen.flow_from_directory(
    train_dir,
    target_size=target_size,
    batch_size=batch_size,
    class_mode='categorical',
    subset='validation',    # 40%
    shuffle=False,
    seed=SEED
)
test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=target_size,
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=False
)

print("class_indices:", train_generator.class_indices)

# ---------------------------
# 5) ëª¨ë¸ êµ¬ì„±: Xception ì „ì´í•™ìŠµ + FC 3ì¸µ
# ---------------------------
base = Xception(weights="imagenet", include_top=False, input_shape=(224, 224, 3))
base.trainable = False  # 1ë‹¨ê³„: feature extractorë¡œ ë™ê²°

inputs = layers.Input(shape=(224, 224, 3))
x = base(inputs, training=False)
x = layers.GlobalAveragePooling2D()(x)
x = layers.Dense(512, activation='relu')(x)
x = Dropout(0.4)(x)
x = layers.Dense(128, activation='relu')(x)
x = Dropout(0.3)(x)
outputs = layers.Dense(train_generator.num_classes, activation='softmax')(x)
model = models.Model(inputs, outputs)

model.compile(
    optimizer=tf.keras.optimizers.Adam(1e-4),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

early_stop = EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True)
ckpt = ModelCheckpoint("xception_faceshape_best.h5",
                       monitor="val_accuracy", save_best_only=True, verbose=1)

# ---------------------------
# 6) í•™ìŠµ (Epoch=20)
# ---------------------------
history = model.fit(
    train_generator,
    epochs=20,
    validation_data=val_generator,
    callbacks=[early_stop, ckpt]
)

# ---------------------------
# 7) í•™ìŠµ ê³¡ì„  ì €ì¥/í‘œì‹œ
# ---------------------------
plt.figure(figsize=(12,5))
plt.subplot(1,2,1)
plt.plot(history.history['accuracy']); plt.plot(history.history['val_accuracy'])
plt.title('Training vs Validation Accuracy'); plt.xlabel('Epoch'); plt.ylabel('Accuracy')
plt.legend(['Train','Val']); plt.grid(True)

plt.subplot(1,2,2)
plt.plot(history.history['loss']); plt.plot(history.history['val_loss'])
plt.title('Training vs Validation Loss'); plt.xlabel('Epoch'); plt.ylabel('Loss')
plt.legend(['Train','Val']); plt.grid(True)

plt.tight_layout()
# íŒŒì¼ë¡œë„ ì €ì¥
os.makedirs("runs_plots", exist_ok=True)
plt.savefig(os.path.join("runs_plots", "accuracy_loss_curves.png"),
            dpi=150, bbox_inches="tight")
plt.show()

# ---------------------------
# 8) í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ í‰ê°€ (í˜¼ë™í–‰ë ¬/ë¦¬í¬íŠ¸)
# ---------------------------
print("\n[Evaluate on TEST set]")
test_loss, test_acc = model.evaluate(test_generator, verbose=0)
print(f"âœ… Test accuracy: {test_acc:.4f}")

test_generator.reset()
pred = model.predict(test_generator)
y_pred = pred.argmax(axis=1)
y_true = test_generator.classes
idx_to_class = {v: k for k, v in test_generator.class_indices.items()}
target_names = [idx_to_class[i] for i in range(len(idx_to_class))]

print("\n=== Classification Report (TEST) ===")
report = classification_report(y_true, y_pred, target_names=target_names)
print(report)

cm = confusion_matrix(y_true, y_pred)
print("Confusion Matrix:\n", cm)

# í˜¼ë™í–‰ë ¬ ì‹œê°í™” (seaborn ìˆìœ¼ë©´ ì´ë¯¸ì§€ ì €ì¥)
try:
    import seaborn as sns
    plt.figure(figsize=(6,5))
    sns.heatmap(cm, annot=True, fmt="d",
                xticklabels=target_names, yticklabels=target_names)
    plt.title("Confusion Matrix (TEST)")
    plt.xlabel("Predicted"); plt.ylabel("True")
    plt.tight_layout()
    plt.savefig(os.path.join("runs_plots", "confusion_matrix_test.png"),
                dpi=150, bbox_inches="tight")
    plt.show()
except Exception as e:
    print("[WARN] seaborn ë¯¸ì„¤ì¹˜ ë˜ëŠ” ì‹œê°í™” ì‹¤íŒ¨:", e)

# ë¦¬í¬íŠ¸/í˜¼ë™í–‰ë ¬ ì €ì¥
os.makedirs("runs_logs", exist_ok=True)
with open(os.path.join("runs_logs", "classification_report_test.txt"),
          "w", encoding="utf-8") as f:
    f.write(report)
np.savetxt(os.path.join("runs_logs", "confusion_matrix_test.csv"),
           cm, fmt="%d", delimiter=",")

# ---------------------------
# 9) í´ë˜ìŠ¤ë³„ ì´ë¯¸ì§€ ìˆ˜ (í•™ìŠµ í´ë”)
# ---------------------------
print("\nğŸ“Š í•™ìŠµìš© ì–¼êµ´í˜•ë³„ ì´ë¯¸ì§€ ìˆ˜:")
for class_name in sorted(os.listdir(train_dir)):
    class_path = os.path.join(train_dir, class_name)
    if os.path.isdir(class_path):
        count = len([f for f in os.listdir(class_path)
                     if f.lower().endswith(('.jpg', '.jpeg', '.png'))])
        print(f"ğŸŸ¢ {class_name}: {count}ì¥")

# ---------------------------
# 10) Train/Test ê°„ íŒŒì¼ëª… ì¤‘ë³µ ì²´í¬
# ---------------------------
def find_common_images(train_dir, test_dir):
    train_images = set()
    test_images = set()

    for class_folder in os.listdir(train_dir):
        class_path = os.path.join(train_dir, class_folder)
        if not os.path.isdir(class_path):
            continue
        for img in os.listdir(class_path):
            if img.lower().endswith(('.jpg', '.jpeg', '.png')):
                train_images.add(img)

    for class_folder in os.listdir(test_dir):
        class_path = os.path.join(test_dir, class_folder)
        if not os.path.isdir(class_path):
            continue
        for img in os.listdir(class_path):
            if img.lower().endswith(('.jpg', '.jpeg', '.png')):
                test_images.add(img)

    common = train_images & test_images
    print(f"\nğŸ” ì¤‘ë³µëœ ì´ë¯¸ì§€ íŒŒì¼ ìˆ˜: {len(common)}ê°œ")
    if common:
        print("ğŸ“‚ ì¤‘ë³µ íŒŒì¼ ì˜ˆì‹œ (ìµœëŒ€ 10ê°œ):")
        for i, name in enumerate(sorted(common)):
            print(f"  - {name}")
            if i >= 9:
                break
    else:
        print("âœ… í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ê°„ íŒŒì¼ëª… ì¤‘ë³µ ì—†ìŒ")

find_common_images(train_dir, test_dir)

# ---------------------------
# 11) ëª¨ë¸ ì €ì¥
# ---------------------------
model.save("model_face_shape_xception.keras")
print("\nâœ… Saved: model_face_shape_xception.keras, xception_faceshape_best.h5, plots/logs in runs_*")
